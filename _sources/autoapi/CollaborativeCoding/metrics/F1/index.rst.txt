CollaborativeCoding.metrics.F1
==============================

.. py:module:: CollaborativeCoding.metrics.F1


Classes
-------

.. autoapisummary::

   CollaborativeCoding.metrics.F1.F1Score


Module Contents
---------------

.. py:class:: F1Score(num_classes, macro_averaging=False)

   Bases: :py:obj:`torch.nn.Module`


   Computes the F1 score for classification tasks with support for both macro and micro averaging.

   This class allows you to compute the F1 score during training or evaluation. You can select between two methods of averaging:
   - **Micro Averaging**: Computes the F1 score globally, treating each individual prediction as equally important.
   - **Macro Averaging**: Computes the F1 score for each class individually and then averages the scores.

   Parameters
   ----------
   num_classes : int
       The number of classes in the classification task.

   macro_averaging : bool, optional, default=False
       If True, computes the macro-averaged F1 score. If False, computes the micro-averaged F1 score. Default is micro averaging.

   Attributes
   ----------
   num_classes : int
       The number of classes in the classification task.

   macro_averaging : bool
       A flag to determine whether to compute the macro-averaged or micro-averaged F1 score.

   y_true : list
       A list to store true labels for the current batch.

   y_pred : list
       A list to store predicted labels for the current batch.

   Methods
   -------
   forward(target, preds)
       Stores predictions and true labels for computing the F1 score during training or evaluation.

   compute_f1()
       Computes and returns the F1 score based on the stored predictions and true labels.

   _micro_F1(target, preds)
       Computes the micro-averaged F1 score based on the global true positive, false positive, and false negative counts.

   _macro_F1(target, preds)
       Computes the macro-averaged F1 score by calculating the F1 score per class and then averaging across all classes.

   __returnmetric__()
       Computes and returns the F1 score (Micro or Macro) as specified.

   __reset__()
       Resets the stored predictions and true labels, preparing for the next batch or epoch.


   .. py:attribute:: num_classes


   .. py:attribute:: macro_averaging
      :value: False



   .. py:attribute:: y_true
      :value: []



   .. py:attribute:: y_pred
      :value: []



   .. py:method:: forward(target, preds)

      Stores the true labels and predictions to compute the F1 score.

      Parameters
      ----------
      target : torch.Tensor
          True labels (shape: [batch_size]).

      preds : torch.Tensor
          Predicted logits (shape: [batch_size, num_classes]).



   .. py:method:: _micro_F1(target, preds)

      Computes the Micro-averaged F1 score (global TP, FP, FN).



   .. py:method:: _macro_F1(target, preds)

      Computes the Macro-averaged F1 score.



   .. py:method:: __returnmetric__()

      Computes and returns the F1 score (Micro or Macro) based on the stored predictions and targets.

      Returns
      -------
      torch.Tensor
          The computed F1 score. Returns NaN if no predictions or targets are available.



   .. py:method:: __reset__()

      Resets the stored predictions and targets for the next batch or epoch.



